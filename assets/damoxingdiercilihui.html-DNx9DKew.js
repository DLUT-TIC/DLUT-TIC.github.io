import{_ as e,r as i,o as p,c as m,d as s,e as a,a as l,b as n}from"./app-jJ6iVhMY.js";const c={},r=n(`<blockquote><p>[!warning] 文档内容可能存在些许错误</p></blockquote><h2 id="前置条件" tabindex="-1"><a class="header-anchor" href="#前置条件"><span>前置条件</span></a></h2><h6 id="环境-推荐新建一个环境" tabindex="-1"><a class="header-anchor" href="#环境-推荐新建一个环境"><span>环境（推荐新建一个环境）</span></a></h6><ul><li>一个虚拟环境</li></ul><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="line">conda create <span class="token parameter variable">-n</span> yourname</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><ul><li><strong>jupyter lab</strong> （如果有装anaconda的话已经安装好了）</li><li>将新的虚拟环境加入notebook中</li></ul><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="line"><span class="token comment"># 在base环境下</span></span>
<span class="line">conda activate</span>
<span class="line">conda <span class="token function">install</span> nb_conda_kernels</span>
<span class="line"></span>
<span class="line"><span class="token comment"># 在要打开的环境</span></span>
<span class="line">conda activate your_env_name</span>
<span class="line">conda <span class="token function">install</span> ipykernel</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h6 id="依赖项" tabindex="-1"><a class="header-anchor" href="#依赖项"><span>依赖项</span></a></h6><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre class="language-python"><code><span class="line">pip install <span class="token operator">-</span><span class="token operator">-</span>upgrade openai</span>
<span class="line">pip <span class="token builtin">list</span>  <span class="token comment"># 查看有没有成功安装</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><h6 id="注册moonshot-api" tabindex="-1"><a class="header-anchor" href="#注册moonshot-api"><span>注册moonshot API</span></a></h6>`,10),o=s("s",null,"token免费送！",-1),h={href:"https://platform.moonshot.cn/console/account",target:"_blank",rel:"noopener noreferrer"},u=n('<h2 id="大概纲要" tabindex="-1"><a class="header-anchor" href="#大概纲要"><span>大概纲要</span></a></h2><ul><li>Transformer <ul><li>Seq2Seq</li><li>self-attention</li><li>Encoder</li><li>Decoder <ul><li>softmax</li></ul></li><li>Encoder-decoder</li></ul></li><li>API参数 <ul><li>OpenAI为例</li></ul></li></ul><h2 id="transformer" tabindex="-1"><a class="header-anchor" href="#transformer"><span>Transformer</span></a></h2><p>^48eae8</p><p><img src="https://raw.githubusercontent.com/Emisaber/pic_obsidian/main/Pasted image 20240712122336.png" alt="Pasted image 20240712122336"></p><h4 id="seq2seq" tabindex="-1"><a class="header-anchor" href="#seq2seq"><span>Seq2Seq</span></a></h4><p><strong>Seq2Seq</strong>（Sequence to Sequence，序列到序列模型）<br> 包括<strong>编码器(Encoder)</strong>，<strong>解码器(Decoder)</strong> 两部分。<br> Seq2Seq 输出不定长度的序列</p><blockquote><p>[!什么可以是不定长度的序列] 文字 语音(音频)</p><ul><li>语音识别，语音翻译，聊天 图片</li><li>拆解图像，RGB三维向量</li></ul></blockquote><h4 id="self-attention" tabindex="-1"><a class="header-anchor" href="#self-attention"><span>self-attention</span></a></h4><p><img src="https://raw.githubusercontent.com/Emisaber/pic_obsidian/main/Pasted image 20240629101948.png" alt="Pasted image 20240629101948|500"> 整个序列(向量组)输入，综合考虑所有输入，输出对应个数的结果</p>',10),g=s("li",null,[s("p",null,"每一个输出都考虑到所有输入的资讯")],-1),d=s("li",null,[s("p",null,"self-attention和FC交替使用")],-1),y={href:"https://arxiv.org/abs/1706.03762",target:"_blank",rel:"noopener noreferrer"},v=n('<li><p><strong>为什么要有自注意力机制</strong>？</p><ul><li><strong>找向量之间的关联性</strong><img src="https://raw.githubusercontent.com/Emisaber/pic_obsidian/main/Pasted image 20240629102644.png" alt="Pasted image 20240629102644|400"></li></ul></li><li><p><strong>注意力怎么算</strong></p><ul><li><strong>Dot-product</strong> 点乘<br><img src="https://raw.githubusercontent.com/Emisaber/pic_obsidian/main/Pasted image 20240629103029.png" alt="Pasted image 20240629103029|343"> 假设只有两个输入，给定两个输入，一个作为query，一个作为key<br> 与两个权重矩阵相乘，再进行点乘</li></ul></li>',2),k=s("h5",{id:"具体怎么做",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#具体怎么做"},[s("span",null,"具体怎么做")])],-1),b=s("p",null,[s("img",{src:"https://raw.githubusercontent.com/Emisaber/pic_obsidian/main/Pasted image 20240629104235.png",alt:"Pasted image 20240629104235|500"}),a(" 输入向量$$a_1,a_2,a_3, a_4.....$$")],-1),x=s("p",null,[s("strong",null,"token")],-1),w=s("p",null,[a("取一个向量做query"),s("br"),a(" 剩下的向量key都与它算注意力")],-1),f=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("msup",null,[s("mi",null,"q"),s("mn",null,"1")]),s("mo",null,"="),s("msup",null,[s("mi",null,"W"),s("mi",null,"q")]),s("msup",null,[s("mi",null,"a"),s("mn",null,"1")])]),s("annotation",{encoding:"application/x-tex"}," q^1 = W^qa^1 ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0585em","vertical-align":"-0.1944em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"q"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8641em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"1")])])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8641em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"W"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7144em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03588em"}},"q")])])])])])])]),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"a"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8641em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"1")])])])])])])])])])])])],-1),z=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("msup",null,[s("mi",null,"k"),s("mn",null,"2")]),s("mo",null,"="),s("msup",null,[s("mi",null,"W"),s("mi",null,"k")]),s("msup",null,[s("mi",null,"a"),s("mn",null,"2")])]),s("annotation",{encoding:"application/x-tex"}," k^2 = W^ka^2 ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8641em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03148em"}},"k"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8641em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"2")])])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8991em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"W"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8991em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03148em"}},"k")])])])])])])]),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"a"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8641em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"2")])])])])])])])])])])])],-1),_=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("msup",null,[s("mi",null,"k"),s("mn",null,"3")]),s("mo",null,"="),s("msup",null,[s("mi",null,"W"),s("mi",null,"k")]),s("msup",null,[s("mi",null,"a"),s("mn",null,"3")])]),s("annotation",{encoding:"application/x-tex"}," k^3 = W^ka^3 ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8641em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03148em"}},"k"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8641em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"3")])])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8991em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"W"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8991em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03148em"}},"k")])])])])])])]),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"a"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8641em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"3")])])])])])])])])])])])],-1),M=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("msup",null,[s("mi",null,"k"),s("mn",null,"4")]),s("mo",null,"="),s("msup",null,[s("mi",null,"W"),s("mi",null,"k")]),s("msup",null,[s("mi",null,"a"),s("mn",null,"4")])]),s("annotation",{encoding:"application/x-tex"}," k^4 = W^ka^4 ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8641em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03148em"}},"k"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8641em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"4")])])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8991em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"W"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8991em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03148em"}},"k")])])])])])])]),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"a"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8641em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"4")])])])])])])])])])])])],-1),P=s("blockquote",null,[s("p",null,"上标是第几个")],-1),q=s("ul",null,[s("li",null,"q与每个k计算注意力分数 attention score")],-1),L=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"a"),s("mrow",null,[s("mn",null,"1"),s("mo",{separator:"true"},","),s("mi",null,"i")])]),s("mo",null,"="),s("msup",null,[s("mi",null,"q"),s("mn",null,"1")]),s("mo",{separator:"true"},"⋅"),s("msup",null,[s("mi",null,"k"),s("mi",null,"i")])]),s("annotation",{encoding:"application/x-tex"}," a_{1,i} = q^1·k^i ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.7167em","vertical-align":"-0.2861em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"a"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"1"),s("span",{class:"mpunct mtight"},","),s("span",{class:"mord mathnormal mtight"},"i")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2861em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0691em","vertical-align":"-0.1944em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"q"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8641em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"1")])])])])])])]),s("span",{class:"mpunct"},"⋅"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03148em"}},"k"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8747em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])])])])])])])])])])],-1),E=s("p",null,"实际上会和自己做关联性 (效果比较好)",-1),j=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"a"),s("mrow",null,[s("mn",null,"1"),s("mo",{separator:"true"},","),s("mn",null,"1")])]),s("mo",null,"="),s("msup",null,[s("mi",null,"q"),s("mn",null,"1")]),s("mo",{separator:"true"},"⋅"),s("msup",null,[s("mi",null,"k"),s("mn",null,"1")])]),s("annotation",{encoding:"application/x-tex"}," a_{1,1} = q^1·k^1 ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.7167em","vertical-align":"-0.2861em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"a"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"1"),s("span",{class:"mpunct mtight"},","),s("span",{class:"mord mtight"},"1")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2861em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0585em","vertical-align":"-0.1944em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"q"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8641em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"1")])])])])])])]),s("span",{class:"mpunct"},"⋅"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03148em"}},"k"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8641em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"1")])])])])])])])])])])])],-1),A=s("p",null,"然后过一层softmax",-1),W=s("ul",null,[s("li",null,"更像是归一化 e")],-1),T=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("msubsup",null,[s("mi",null,"a"),s("mrow",null,[s("mn",null,"1"),s("mo",{separator:"true"},","),s("mi",null,"i")]),s("mo",{mathvariant:"normal",lspace:"0em",rspace:"0em"},"′")]),s("mo",null,"="),s("mfrac",null,[s("mrow",null,[s("mi",null,"e"),s("mi",null,"x"),s("mi",null,"p"),s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"a"),s("mrow",null,[s("mn",null,"1"),s("mo",{separator:"true"},","),s("mi",null,"i")])]),s("mo",{stretchy:"false"},")")]),s("mrow",null,[s("munderover",null,[s("mo",null,"∑"),s("mi",null,"j"),s("mi",null,"N")]),s("mi",null,"e"),s("mi",null,"x"),s("mi",null,"p"),s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"a"),s("mrow",null,[s("mn",null,"1"),s("mo",{separator:"true"},","),s("mi",null,"j")])]),s("mo",{stretchy:"false"},")")])])]),s("annotation",{encoding:"application/x-tex"}," a_{1,i}' = \\frac{exp(a_{1,i})}{\\sum_j^Nexp(a_{1,j})} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.185em","vertical-align":"-0.3831em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"a"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8019em"}},[s("span",{style:{top:"-2.453em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"1"),s("span",{class:"mpunct mtight"},","),s("span",{class:"mord mathnormal mtight"},"i")])])]),s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"′")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3831em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.734em","vertical-align":"-1.307em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.427em"}},[s("span",{style:{top:"-2.1288em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mop"},[s("span",{class:"mop op-symbol small-op",style:{position:"relative",top:"0em"}},"∑"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.9812em"}},[s("span",{style:{top:"-2.4003em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05724em"}},"j")])]),s("span",{style:{top:"-3.2029em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.10903em"}},"N")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.4358em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"e"),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mord mathnormal"},"p"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"a"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"1"),s("span",{class:"mpunct mtight"},","),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05724em"}},"j")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2861em"}},[s("span")])])])])]),s("span",{class:"mclose"},")")])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"e"),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mord mathnormal"},"p"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"a"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"1"),s("span",{class:"mpunct mtight"},","),s("span",{class:"mord mathnormal mtight"},"i")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2861em"}},[s("span")])])])])]),s("span",{class:"mclose"},")")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.307em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})])])])])])],-1),I=s("p",null,[s("img",{src:"https://raw.githubusercontent.com/Emisaber/pic_obsidian/main/Pasted image 20240629110514.png",alt:"Pasted image 20240629110514|550"})],-1),S=s("p",null,[a("再然后抽取重要的资讯"),s("br"),s("img",{src:"https://raw.githubusercontent.com/Emisaber/pic_obsidian/main/Pasted image 20240629110042.png",alt:"Pasted image 20240629110042|550"}),s("br"),a(" 原向量再乘以一个矩阵，计算没加入注意力分数的原本输出")],-1),N=s("ul",null,[s("li",null,"如果没有自注意力机制，直接过FC的话就是一个加权和"),s("li",null,"在这里就是计算原来不考虑相关度的加权分数"),s("li",null,"在这样的基础上再根据注意力分数做一次加权")],-1),D=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("msup",null,[s("mi",null,"v"),s("mi",null,"i")]),s("mo",null,"="),s("msup",null,[s("mi",null,"W"),s("mi",null,"v")]),s("msup",null,[s("mi",null,"a"),s("mi",null,"i")])]),s("annotation",{encoding:"application/x-tex"}," v^i = W^va^i ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8747em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"v"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8747em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8747em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"W"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7144em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03588em"}},"v")])])])])])])]),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"a"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8747em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])])])])])])])])])])],-1),F=s("p",null,[a("每个"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msup",null,[s("mi",null,"v"),s("mi",null,"i")])]),s("annotation",{encoding:"application/x-tex"},"v^i")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8247em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"v"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8247em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])])])])])])])])]),a("都与分数相乘，加和得到"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msup",null,[s("mi",null,"a"),s("mn",null,"1")])]),s("annotation",{encoding:"application/x-tex"},"a^1")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8141em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"a"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8141em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"1")])])])])])])])])])]),a(" 过自注意力之后的输出 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msup",null,[s("mi",null,"b"),s("mn",null,"1")])]),s("annotation",{encoding:"application/x-tex"},"b^1")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8141em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"b"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8141em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"1")])])])])])])])])])])],-1),V=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("msup",null,[s("mi",null,"b"),s("mn",null,"1")]),s("mo",null,"="),s("munder",null,[s("mo",null,"∑"),s("mi",null,"i")]),s("msubsup",null,[s("mi",null,"a"),s("mrow",null,[s("mn",null,"1"),s("mo",{separator:"true"},","),s("mi",null,"i")]),s("mo",{mathvariant:"normal",lspace:"0em",rspace:"0em"},"′")]),s("msub",null,[s("mi",null,"v"),s("mi",null,"i")])]),s("annotation",{encoding:"application/x-tex"}," b^1 = \\sum_ia_{1,i}'v_i ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8641em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"b"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8641em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"1")])])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.3277em","vertical-align":"-1.2777em"}}),s("span",{class:"mop op-limits"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.05em"}},[s("span",{style:{top:"-1.8723em","margin-left":"0em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])]),s("span",{style:{top:"-3.05em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",null,[s("span",{class:"mop op-symbol large-op"},"∑")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.2777em"}},[s("span")])])])]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"a"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8019em"}},[s("span",{style:{top:"-2.453em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"1"),s("span",{class:"mpunct mtight"},","),s("span",{class:"mord mathnormal mtight"},"i")])])]),s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"′")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3831em"}},[s("span")])])])])]),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"v"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0359em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])])])],-1),C=s("ul",null,[s("li",null,[a("如果和"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msup",null,[s("mi",null,"a"),s("mn",null,"1")])]),s("annotation",{encoding:"application/x-tex"},"a^1")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8141em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"a"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8141em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"1")])])])])])])])])])]),a(" 的关联度很高的话，注意力分数就会很高，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msup",null,[s("mi",null,"v"),s("mi",null,"i")])]),s("annotation",{encoding:"application/x-tex"},"v^i")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8247em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"v"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8247em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])])])])])])])])]),a("和注意力分数相乘就会比较大，在"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msup",null,[s("mi",null,"b"),s("mn",null,"1")])]),s("annotation",{encoding:"application/x-tex"},"b^1")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8141em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"b"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8141em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"1")])])])])])])])])])]),a("中占比就大，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msup",null,[s("mi",null,"b"),s("mn",null,"1")])]),s("annotation",{encoding:"application/x-tex"},"b^1")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8141em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"b"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8141em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"1")])])])])])])])])])]),a("就体现了比较多的它的信息")]),s("li",null,[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msup",null,[s("mi",null,"b"),s("mrow",null,[s("mn",null,"1"),s("mo",null,"−"),s("mi",null,"n")])])]),s("annotation",{encoding:"application/x-tex"},"b^{1-n}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8141em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"b"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8141em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"1"),s("span",{class:"mbin mtight"},"−"),s("span",{class:"mord mathnormal mtight"},"n")])])])])])])])])])])]),a("是一起算的，没有顺序的概念")])],-1),K=n('<h6 id="小总结" tabindex="-1"><a class="header-anchor" href="#小总结"><span>小总结</span></a></h6><p>到这里，self-attention有三部分</p><ul><li>计算关联度/注意力分数（dot-product）</li><li>过一层softmax</li><li>提取重要资讯(相乘加和)</li></ul><p>几个点</p><ul><li>单位是向量，输入是多个向量</li><li>对向量内部的加权是通过矩阵乘法实现的</li><li>原本只有计算v然后加权和(只有FC的话)</li><li>现在权重改成注意力分数的归一化</li></ul><h6 id="矩阵的话" tabindex="-1"><a class="header-anchor" href="#矩阵的话"><span>矩阵的话</span></a></h6><p><img src="https://raw.githubusercontent.com/Emisaber/pic_obsidian/main/Pasted image 20240630100136.png" alt="Pasted image 20240630100136|480"></p><ul><li>每一个a都得进行一次矩阵乘法计算query</li><li>每一个a都得进行一次矩阵乘法计算key</li><li>同理v也是 所以如果用矩阵的角度<br> 计算query，key，v</li></ul>',8),B=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"Q"),s("mo",null,"="),s("msup",null,[s("mi",null,"W"),s("mi",null,"q")]),s("mi",null,"I")]),s("annotation",{encoding:"application/x-tex"}," Q = W^qI ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8778em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal"},"Q"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.7144em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"W"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7144em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03588em"}},"q")])])])])])])]),s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"I")])])])])],-1),O=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"K"),s("mo",null,"="),s("msup",null,[s("mi",null,"W"),s("mi",null,"k")]),s("mi",null,"I")]),s("annotation",{encoding:"application/x-tex"}," K = W^kI ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.07153em"}},"K"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8991em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"W"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8991em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03148em"}},"k")])])])])])])]),s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"I")])])])])],-1),Q=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"V"),s("mo",null,"="),s("msup",null,[s("mi",null,"W"),s("mi",null,"v")]),s("mi",null,"I")]),s("annotation",{encoding:"application/x-tex"}," V = W^vI ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.22222em"}},"V"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.7144em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"W"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7144em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03588em"}},"v")])])])])])])]),s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"I")])])])])],-1),R=s("p",null,[a("计算注意力分数"),s("br"),s("img",{src:"https://raw.githubusercontent.com/Emisaber/pic_obsidian/main/Pasted image 20240630100930.png",alt:"Pasted image 20240630100930"})],-1),Y=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("msup",null,[s("mi",null,"K"),s("mi",null,"T")]),s("msup",null,[s("mtext",{mathvariant:"bold"},"q"),s("mi",null,"i")]),s("mo",null,"="),s("msub",null,[s("mtext",{mathvariant:"bold"},"a"),s("mi",null,"i")])]),s("annotation",{encoding:"application/x-tex"}," K^T\\textbf{q}^i = \\textbf{a}_{i} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0858em","vertical-align":"-0.1944em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07153em"}},"K"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8913em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.13889em"}},"T")])])])])])])]),s("span",{class:"mord"},[s("span",{class:"mord text"},[s("span",{class:"mord textbf"},"q")]),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8747em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.5944em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord text"},[s("span",{class:"mord textbf"},"a")]),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])])])],-1),$=s("p",null,"则计算所有注意力分数",-1),G=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("msup",null,[s("mi",null,"K"),s("mi",null,"T")]),s("mi",null,"Q"),s("mo",null,"="),s("mi",null,"A")]),s("annotation",{encoding:"application/x-tex"}," K^TQ = A ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0858em","vertical-align":"-0.1944em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07153em"}},"K"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8913em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.13889em"}},"T")])])])])])])]),s("span",{class:"mord mathnormal"},"Q"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord mathnormal"},"A")])])])])],-1),J=s("p",null,"然后归一化",-1),H=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"s"),s("mi",null,"o"),s("mi",null,"f"),s("mi",null,"t"),s("mi",null,"m"),s("mi",null,"a"),s("mi",null,"x"),s("mo",{stretchy:"false"},"("),s("mi",null,"A"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("msup",null,[s("mi",null,"A"),s("mo",{mathvariant:"normal",lspace:"0em",rspace:"0em"},"′")])]),s("annotation",{encoding:"application/x-tex"}," softmax(A) = A' ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"so"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mord mathnormal"},"t"),s("span",{class:"mord mathnormal"},"ma"),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"A"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8019em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"A"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8019em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"′")])])])])])])])])])])])])],-1),U=s("ul",null,[s("li",null,[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msup",null,[s("mi",null,"A"),s("mo",{mathvariant:"normal",lspace:"0em",rspace:"0em"},"′")])]),s("annotation",{encoding:"application/x-tex"},"A'")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.7519em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"A"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7519em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"′")])])])])])])])])])])]),a("称Attention Matric")])],-1),X=s("p",null,"计算最终分数",-1),Z=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"O"),s("mo",null,"="),s("mi",null,"V"),s("msup",null,[s("mi",null,"A"),s("mo",{mathvariant:"normal",lspace:"0em",rspace:"0em"},"′")])]),s("annotation",{encoding:"application/x-tex"}," O = VA' ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"O"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8019em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.22222em"}},"V"),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"A"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8019em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"′")])])])])])])])])])])])])],-1),ss=n('<p>所以全程就是一套矩阵乘法，只有三个权重矩阵是未知的(学习的)</p><h6 id="multi-head-self-attention" tabindex="-1"><a class="header-anchor" href="#multi-head-self-attention"><span>Multi-head self-attention</span></a></h6><p>可能会有不同类型的相关度(different type of relevance)</p><ul><li>需要多个query和多个key确定不同类型的相关度</li><li>需要多个v来计算输出<br><img src="https://raw.githubusercontent.com/Emisaber/pic_obsidian/main/Pasted image 20240701084105.png" alt="Pasted image 20240701084105|600"></li><li>然后照常计算(分开算<br><img src="https://raw.githubusercontent.com/Emisaber/pic_obsidian/main/Pasted image 20240701084304.png" alt="Pasted image 20240701084304|550"></li><li>然后转化输出 <img src="https://raw.githubusercontent.com/Emisaber/pic_obsidian/main/Pasted image 20240701084339.png" alt="Pasted image 20240701084339|491"></li></ul><h6 id="positional-encoding" tabindex="-1"><a class="header-anchor" href="#positional-encoding"><span>Positional Encoding</span></a></h6><p>到这里，注意力的计算和位置无关，完全就是两个向量本身的相关度，只要是相同的向量，无论出现在向量序列的哪里算出来的注意力分数都一样</p><p>加上一个位置的偏移</p>',7),as=s("ul",null,[s("li",null,[a("为每一个位置配备一个偏移向量---位置向量(positional vector) "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msup",null,[s("mi",null,"e"),s("mi",null,"i")])]),s("annotation",{encoding:"application/x-tex"},"e^i")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8247em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8247em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])])])])])])])])])]),s("li",null,"然后每次这个位置的输入都加上这个偏移"),s("li",null,[s("img",{src:"https://raw.githubusercontent.com/Emisaber/pic_obsidian/main/Pasted image 20240701090055.png",alt:"Pasted image 20240701090055|351"})])],-1),ns=n('<h4 id="encoder" tabindex="-1"><a class="header-anchor" href="#encoder"><span>Encoder</span></a></h4><p><img src="https://raw.githubusercontent.com/Emisaber/pic_obsidian/main/Pasted image 20240416162315.png" alt="Pasted image 20240416162315"></p><p>实际的Transformer中，self-attention之后，还将input加到output中——<strong>residual connection</strong><br><img src="https://raw.githubusercontent.com/Emisaber/pic_obsidian/main/Pasted image 20240416162822.png" alt="Pasted image 20240416162822"><br> 然后对<strong>a+b</strong>进行<strong>layer normalization</strong><br><img src="https://raw.githubusercontent.com/Emisaber/pic_obsidian/main/Pasted image 20240416162947.png" alt="Pasted image 20240416162947"></p><p>对输入计算mean和standard deviation，做归一化<br><img src="https://raw.githubusercontent.com/Emisaber/pic_obsidian/main/Pasted image 20240416163228.png" alt="Pasted image 20240416163228"></p><h4 id="decoder" tabindex="-1"><a class="header-anchor" href="#decoder"><span>Decoder</span></a></h4><p><img src="https://raw.githubusercontent.com/Emisaber/pic_obsidian/main/Pasted image 20240416165138.png" alt="Pasted image 20240416165138|"></p><ul><li><strong>special token</strong>作为开始 <ul><li>用one-hot vector 表示，一维1，其他0</li></ul></li><li>吃到begin后，输出一个<strong>向量</strong><ul><li>和vocabulary(希望输出的内容)一样大 （例如常见的3000千方块字）</li><li>输出的向量会进行一次[[softmax]]，得到各个token的<strong>分数</strong>，最高最为输出。</li></ul></li></ul><p><img src="https://raw.githubusercontent.com/Emisaber/pic_obsidian/main/Pasted image 20240416165504.png" alt="Pasted image 20240416165504"></p><ul><li>上一个输出不断加到输入中 <ul><li>表示为one-hot vector</li><li>前面均作为输入？</li><li><strong>其实encoder也有输入</strong></li></ul></li><li>由于decoder将自己的输出作为输入，所以有可能会有<strong>error propagation</strong>的问题</li></ul><h6 id="那怎么停止" tabindex="-1"><a class="header-anchor" href="#那怎么停止"><span>那怎么停止</span></a></h6><ul><li>直到输出special token 作为<strong>END</strong></li></ul><h6 id="masked-self-attention" tabindex="-1"><a class="header-anchor" href="#masked-self-attention"><span>Masked self attention</span></a></h6><p><img src="https://raw.githubusercontent.com/Emisaber/pic_obsidian/main/Pasted image 20240416174950.png" alt="Pasted image 20240416174950"></p><ul><li>原本就是一个个产生的，只能考虑已经生成的部分</li><li>所以需要把后面的都掩藏起来，称为sequence mask</li><li>此外还有padding mask</li></ul><h4 id="encoder-decoder" tabindex="-1"><a class="header-anchor" href="#encoder-decoder"><span>Encoder-Decoder</span></a></h4><p><img src="https://raw.githubusercontent.com/Emisaber/pic_obsidian/main/Pasted image 20240416181240.png" alt="Pasted image 20240416181240"></p><p>将输入喂给Encoder，给Decoder一个Begin，Encoder输出后(多个向量)与Decoder第一次归一化后的输出(一个向量)进入self-attention计算attention分数。<br><img src="https://raw.githubusercontent.com/Emisaber/pic_obsidian/main/Pasted image 20240416183053.png" alt="Pasted image 20240416183053|400"></p><p>中间计算attention的过程称<strong>cross attention</strong><br> 通过第一个q，decoder从什么都没有去encoder中获得信息，信息不断迭代进入下一轮。<br> 实际上decoder很多层，每一层都拿了encoder最后一层的输出。</p><h2 id="api-参数" tabindex="-1"><a class="header-anchor" href="#api-参数"><span>API 参数</span></a></h2><ul><li>API参数 <ul><li>OpenAI为例 <ul><li><code>system</code>: 固定的prompt</li><li><code>user</code>：用户输入</li><li><code>assistant</code>：模型的回答</li></ul></li><li>各个参数 <ul><li><code>max_tokens</code>：最大的token数量</li><li><code>temperature</code>：温度</li><li><code>top_p</code>：分布函数</li><li><code>n</code>：n个回答</li><li><code>stop</code>：指明停止的token</li><li><code>tools</code>：工具（函数）的说明</li><li><code>logprobs</code>：是否返回每个token的概率</li><li><code>logit_bias</code>：对某个词的概率偏差</li></ul></li><li>function call <ul><li>大概的流程</li><li><img src="https://raw.githubusercontent.com/Emisaber/pic_obsidian/main/Pasted image 20240711110318.png" alt="Pasted image 20240711110318"></li></ul></li></ul></li></ul><h3 id="关于softmax" tabindex="-1"><a class="header-anchor" href="#关于softmax"><span>关于softmax</span></a></h3><p>softmax是一个归一化函数，接受实数向量，计算出对应的归一化的概率向量，并保证每个数都大于或等于0。</p><p>softmax 定义式是：</p>',23),ts=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"s"),s("mi",null,"o"),s("mi",null,"f"),s("mi",null,"t"),s("mi",null,"m"),s("mi",null,"a"),s("mi",null,"x"),s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"x"),s("mi",null,"i")]),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mfrac",null,[s("msup",null,[s("mi",null,"e"),s("msub",null,[s("mi",null,"x"),s("mi",null,"i")])]),s("mrow",null,[s("munderover",null,[s("mo",null,"∑"),s("mrow",null,[s("mi",null,"j"),s("mo",null,"="),s("mn",null,"1")]),s("mi",null,"n")]),s("msup",null,[s("mi",null,"e"),s("msub",null,[s("mi",null,"x"),s("mi",null,"j")])])])])]),s("annotation",{encoding:"application/x-tex"}," softmax(x_i) = \\frac{e^{x_i}}{\\sum_{j=1}^ne^{x_j}} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"so"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mord mathnormal"},"t"),s("span",{class:"mord mathnormal"},"ma"),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.4715em","vertical-align":"-1.1301em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3414em"}},[s("span",{style:{top:"-2.3057em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mop"},[s("span",{class:"mop op-symbol small-op",style:{position:"relative",top:"0em"}},"∑"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8043em"}},[s("span",{style:{top:"-2.4003em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05724em"}},"j"),s("span",{class:"mrel mtight"},"="),s("span",{class:"mord mtight"},"1")])])]),s("span",{style:{top:"-3.2029em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"n")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.4358em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6065em"}},[s("span",{style:{top:"-3.0051em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3281em"}},[s("span",{style:{top:"-2.357em","margin-left":"0em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.5em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05724em"}},"j")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2819em"}},[s("span")])])])])])])])])])])])])])])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6644em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3281em"}},[s("span",{style:{top:"-2.357em","margin-left":"0em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.5em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.143em"}},[s("span")])])])])])])])])])])])])])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.1301em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})])])])])])],-1),ls=s("p",null,[a("粗略的看，softmax是one-hot(argmax)的光滑近似"),s("br"),a(" argmax在一个向量中取出最大值所在的位置，one-hot(i)生成第i位为1，其余为0的向量")],-1),es=s("h5",{id:"详见",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#详见"},[s("span",null,"详见")])],-1),is={href:"https://allenwind.github.io/blog/9905/",target:"_blank",rel:"noopener noreferrer"},ps={href:"https://allenwind.github.io/blog/15110/",target:"_blank",rel:"noopener noreferrer"},ms=n(`<h3 id="sampling" tabindex="-1"><a class="header-anchor" href="#sampling"><span>Sampling</span></a></h3><p>pre:</p><ul><li>softmax aim at:</li><li>temperature sample</li><li>nucleus sample (top-p)</li><li>top-k</li></ul><p>语言模型的输出(GPT-2)是通过自回归的方式输出的，将当前输出的token迭代进行下一次的预测，计算分布，得到概率输出。但是这样的输出经常出现问题(stuck or loop)</p><ul><li>如果只选最优概率，可能导致stuck and loop（注意力集中在后几个）</li><li>取样会更好</li><li>随机取可能会有很大一部分token和答案毫不相关，但是这部分token占有概率，被选中有可能导致推理脱轨</li><li>为了避免选中这些东西，流行的方法有temperature sampling and top k sampling</li></ul><h5 id="temperature-sampling" tabindex="-1"><a class="header-anchor" href="#temperature-sampling"><span>Temperature sampling</span></a></h5><p>inspired by statistical thermodynamics, where high temperature means low energy states are more likely encountered. 低能量的状态遇到的概率更大</p><ul><li>in probability models, logits(the raw output of the final linear layer)</li><li>before feeding to softmax, implement temperature sampling by dividing logits by the temperature.</li><li><strong>高温下，经过softmax，低概率的数的概率相对增大</strong></li></ul><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre class="language-python"><code><span class="line"><span class="token keyword">import</span> torch</span>
<span class="line"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F</span>
<span class="line">temperature <span class="token operator">=</span> <span class="token number">0.5</span>  <span class="token comment"># ex</span></span>
<span class="line">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line">F<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>a<span class="token operator">/</span>temperature<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>in a conclusion Lower temperatures make the model increasingly confident in its top choices, while temperatures greater than 1 decrease confidence.</p></li><li><p>温度越高，随机性越大</p></li><li><p>addition 0 temperature is equivalent to argmax/max likelihood, while infinite temperature corresponds to a uniform sampling.</p></li></ul><h6 id="为什么相对增大" tabindex="-1"><a class="header-anchor" href="#为什么相对增大"><span>为什么相对增大?</span></a></h6><p>softmax 定义式是：</p>`,12),cs=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"s"),s("mi",null,"o"),s("mi",null,"f"),s("mi",null,"t"),s("mi",null,"m"),s("mi",null,"a"),s("mi",null,"x"),s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"x"),s("mi",null,"i")]),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mfrac",null,[s("msup",null,[s("mi",null,"e"),s("msub",null,[s("mi",null,"x"),s("mi",null,"i")])]),s("mrow",null,[s("munderover",null,[s("mo",null,"∑"),s("mrow",null,[s("mi",null,"j"),s("mo",null,"="),s("mn",null,"1")]),s("mi",null,"n")]),s("msup",null,[s("mi",null,"e"),s("msub",null,[s("mi",null,"x"),s("mi",null,"j")])])])])]),s("annotation",{encoding:"application/x-tex"}," softmax(x_i) = \\frac{e^{x_i}}{\\sum_{j=1}^ne^{x_j}} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"so"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mord mathnormal"},"t"),s("span",{class:"mord mathnormal"},"ma"),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.4715em","vertical-align":"-1.1301em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3414em"}},[s("span",{style:{top:"-2.3057em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mop"},[s("span",{class:"mop op-symbol small-op",style:{position:"relative",top:"0em"}},"∑"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8043em"}},[s("span",{style:{top:"-2.4003em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05724em"}},"j"),s("span",{class:"mrel mtight"},"="),s("span",{class:"mord mtight"},"1")])])]),s("span",{style:{top:"-3.2029em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"n")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.4358em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6065em"}},[s("span",{style:{top:"-3.0051em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3281em"}},[s("span",{style:{top:"-2.357em","margin-left":"0em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.5em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05724em"}},"j")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2819em"}},[s("span")])])])])])])])])])])])])])])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6644em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3281em"}},[s("span",{style:{top:"-2.357em","margin-left":"0em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.5em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.143em"}},[s("span")])])])])])])])])])])])])])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.1301em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})])])])])])],-1),rs=s("p",null,[a("加上"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"τ")]),s("annotation",{encoding:"application/x-tex"},"\\tau")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.1132em"}},"τ")])])]),a(" (temperature)")],-1),os=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"s"),s("mi",null,"o"),s("mi",null,"f"),s("mi",null,"t"),s("mi",null,"m"),s("mi",null,"a"),s("mi",null,"x"),s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"x"),s("mi",null,"i")]),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mfrac",null,[s("msup",null,[s("mi",null,"e"),s("mrow",null,[s("msub",null,[s("mi",null,"x"),s("mi",null,"i")]),s("mi",{mathvariant:"normal"},"/"),s("mi",null,"τ")])]),s("mrow",null,[s("munderover",null,[s("mo",null,"∑"),s("mrow",null,[s("mi",null,"j"),s("mo",null,"="),s("mn",null,"1")]),s("mi",null,"n")]),s("msup",null,[s("mi",null,"e"),s("mrow",null,[s("msub",null,[s("mi",null,"x"),s("mi",null,"j")]),s("mi",{mathvariant:"normal"},"/"),s("mi",null,"τ")])])])])]),s("annotation",{encoding:"application/x-tex"}," softmax(x_i) = \\frac{e^{x_i/\\tau}}{\\sum_{j=1}^ne^{x_j/\\tau}} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"so"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mord mathnormal"},"t"),s("span",{class:"mord mathnormal"},"ma"),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.7209em","vertical-align":"-1.1559em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.565em"}},[s("span",{style:{top:"-2.2799em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mop"},[s("span",{class:"mop op-symbol small-op",style:{position:"relative",top:"0em"}},"∑"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8043em"}},[s("span",{style:{top:"-2.4003em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05724em"}},"j"),s("span",{class:"mrel mtight"},"="),s("span",{class:"mord mtight"},"1")])])]),s("span",{style:{top:"-3.2029em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"n")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.4358em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8301em"}},[s("span",{style:{top:"-3.0051em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3281em"}},[s("span",{style:{top:"-2.357em","margin-left":"0em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.5em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05724em"}},"j")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2819em"}},[s("span")])])])])]),s("span",{class:"mord mtight"},"/"),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.1132em"}},"τ")])])])])])])])])])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.888em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3281em"}},[s("span",{style:{top:"-2.357em","margin-left":"0em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.5em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.143em"}},[s("span")])])])])]),s("span",{class:"mord mtight"},"/"),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.1132em"}},"τ")])])])])])])])])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.1559em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})])])])])])],-1),hs=s("ul",null,[s("li",null,[a("对于softmax的值来说，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"x"),s("mi",{mathvariant:"normal"},"/"),s("mi",null,"τ")]),s("annotation",{encoding:"application/x-tex"},"x/\\tau")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mord"},"/"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.1132em"}},"τ")])])]),a(" ，x越大，对于"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msup",null,[s("mi",null,"e"),s("mi",null,"x")])]),s("annotation",{encoding:"application/x-tex"},"e^x")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6644em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6644em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"x")])])])])])])])])])]),a("来说变化的幅度就越大(指数曲线)，所有"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"x"),s("mi",null,"i")])]),s("annotation",{encoding:"application/x-tex"},"x_i")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.5806em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),a("在x上的放大（缩小）倍数是一样的，原来概率大的token softmax出来之后，分子分母变化都大，而概率小的分母变化更大。")]),s("li",null,"当温度低，概率小的token分母增大相对分子更明显，概率随温度低而减小"),s("li",null,"当温度高，概率小的token分母减小相对分子更明显，数值增大，而概率大的相反")],-1),us=s("p",null,[a("所以"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"τ")]),s("annotation",{encoding:"application/x-tex"},"\\tau")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.1132em"}},"τ")])])]),a("越大，低概率token抢占的概率更大，随机性越高。")],-1),gs=n(`<h5 id="top-k-sampling" tabindex="-1"><a class="header-anchor" href="#top-k-sampling"><span>Top k sampling</span></a></h5><p><strong>sorting by probability and zeroing out the probabilities for anything below the k&#39;th token</strong> 除了前k个外都置为0</p><ul><li>it appears to improve the result</li><li>but in some cases, the probabilities of token can not be aparently seperated</li><li>可能多个token都有道理，概率分布的差异并不显著</li><li>propose nucleus(/ˈnjuː.kli.əs/) sampling</li></ul><h5 id="nucleus-sample" tabindex="-1"><a class="header-anchor" href="#nucleus-sample"><span>nucleus sample</span></a></h5><ul><li>top-p sampling, where p is the threshold of the CDF.</li><li>calculate the first n token and cut off as soon as CDF exceed p</li><li>保留了一定的随机性</li></ul><h5 id="why-maximum-likelihood-may-not-work" tabindex="-1"><a class="header-anchor" href="#why-maximum-likelihood-may-not-work"><span>Why maximum likelihood may not work?</span></a></h5><ul><li>it can never see the errors inside the model, it may predict a error token but use &quot;correct&quot; method for the next one, expanding the error.</li><li>或者，当只选取概率最大时，由于注意力只集中在后几个上，所以算出来可能会是单考虑特定token时的答案，此时会导向不合理的结果</li></ul><h5 id="取样之后呢" tabindex="-1"><a class="header-anchor" href="#取样之后呢"><span>取样之后呢</span></a></h5><ul><li>top-p top-k temperature 都是选出区间</li><li>temperature 和 top-k top-p可以一起使用</li><li>在这之后根据概率取样</li></ul><p>根据karpathy的手搓LLama2</p><ul><li>可以是设定一个0到1的随机数(coin)，将概率倒序排列</li><li>当分布函数CDF 取值超过 coin时，选出此时最后一个加入的token</li><li>coin的选定是随机的</li><li>coin落到哪里概率都一样，那coin是否落在一个token的概率范围里只和概率的大小有关，实现了概率取样，得到真正的next token</li></ul><div class="language-c line-numbers-mode" data-highlighter="prismjs" data-ext="c" data-title="c"><pre class="language-c"><code><span class="line"><span class="token keyword">int</span> <span class="token function">sample_mult</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token operator">*</span> probabilities<span class="token punctuation">,</span> <span class="token keyword">int</span> n<span class="token punctuation">,</span> <span class="token keyword">float</span> coin<span class="token punctuation">)</span> <span class="token punctuation">{</span></span>
<span class="line">    <span class="token comment">// sample index from probabilities (they must sum to 1!)</span></span>
<span class="line">    <span class="token comment">// coin is a random number in [0, 1), usually from random_f32()</span></span>
<span class="line">    <span class="token keyword">float</span> cdf <span class="token operator">=</span> <span class="token number">0.0f</span><span class="token punctuation">;</span></span>
<span class="line">    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> n<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span></span>
<span class="line">        cdf <span class="token operator">+=</span> probabilities<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span></span>
<span class="line">        <span class="token keyword">if</span> <span class="token punctuation">(</span>coin <span class="token operator">&lt;</span> cdf<span class="token punctuation">)</span> <span class="token punctuation">{</span></span>
<span class="line">            <span class="token keyword">return</span> i<span class="token punctuation">;</span></span>
<span class="line">        <span class="token punctuation">}</span></span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line">    <span class="token keyword">return</span> n <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">;</span> <span class="token comment">// in case of rounding errors</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>对于top-p来说，最后的计算只需限制前k个里面选，即在概率为cdf里面而不是在1里</p><div class="language-c line-numbers-mode" data-highlighter="prismjs" data-ext="c" data-title="c"><pre class="language-c"><code><span class="line"><span class="token keyword">int</span> <span class="token function">sample_topp</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token operator">*</span> probabilities<span class="token punctuation">,</span> <span class="token keyword">int</span> n<span class="token punctuation">,</span> <span class="token keyword">float</span> topp<span class="token punctuation">,</span> ProbIndex<span class="token operator">*</span> probindex<span class="token punctuation">,</span> <span class="token keyword">float</span> coin<span class="token punctuation">)</span> <span class="token punctuation">{</span></span>
<span class="line">    <span class="token comment">// top-p sampling (or &quot;nucleus sampling&quot;) samples from the smallest set of</span></span>
<span class="line">    <span class="token comment">// tokens that exceed probability topp. This way we never sample tokens that</span></span>
<span class="line">    <span class="token comment">// have very low probabilities and are less likely to go &quot;off the rails&quot;.</span></span>
<span class="line">    <span class="token comment">// coin is a random number in [0, 1), usually from random_f32()</span></span>
<span class="line"></span>
<span class="line">    <span class="token keyword">int</span> n0 <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span></span>
<span class="line">    <span class="token comment">// quicksort indices in descending order of probabilities</span></span>
<span class="line">    <span class="token comment">// values smaller than (1 - topp) / (n - 1) cannot be part of the result</span></span>
<span class="line">    <span class="token comment">// so for efficiency we crop these out as candidates before sorting</span></span>
<span class="line">    <span class="token keyword">const</span> <span class="token keyword">float</span> cutoff <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1.0f</span> <span class="token operator">-</span> topp<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>n <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span></span>
<span class="line">    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> n<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span></span>
<span class="line">        <span class="token keyword">if</span> <span class="token punctuation">(</span>probabilities<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">&gt;=</span> cutoff<span class="token punctuation">)</span> <span class="token punctuation">{</span></span>
<span class="line">            probindex<span class="token punctuation">[</span>n0<span class="token punctuation">]</span><span class="token punctuation">.</span>index <span class="token operator">=</span> i<span class="token punctuation">;</span></span>
<span class="line">            probindex<span class="token punctuation">[</span>n0<span class="token punctuation">]</span><span class="token punctuation">.</span>prob <span class="token operator">=</span> probabilities<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span></span>
<span class="line">            n0<span class="token operator">++</span><span class="token punctuation">;</span></span>
<span class="line">        <span class="token punctuation">}</span></span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line">    <span class="token function">qsort</span><span class="token punctuation">(</span>probindex<span class="token punctuation">,</span> n0<span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span>ProbIndex<span class="token punctuation">)</span><span class="token punctuation">,</span> compare<span class="token punctuation">)</span><span class="token punctuation">;</span></span>
<span class="line"></span>
<span class="line">    <span class="token comment">// truncate the list where cumulative probability exceeds topp</span></span>
<span class="line">    <span class="token keyword">float</span> cumulative_prob <span class="token operator">=</span> <span class="token number">0.0f</span><span class="token punctuation">;</span></span>
<span class="line">    <span class="token keyword">int</span> last_idx <span class="token operator">=</span> n0 <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">;</span> <span class="token comment">// in case of rounding errors consider all elements</span></span>
<span class="line">    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> n0<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span></span>
<span class="line">        cumulative_prob <span class="token operator">+=</span> probindex<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>prob<span class="token punctuation">;</span></span>
<span class="line">        <span class="token keyword">if</span> <span class="token punctuation">(</span>cumulative_prob <span class="token operator">&gt;</span> topp<span class="token punctuation">)</span> <span class="token punctuation">{</span></span>
<span class="line">            last_idx <span class="token operator">=</span> i<span class="token punctuation">;</span></span>
<span class="line">            <span class="token keyword">break</span><span class="token punctuation">;</span> <span class="token comment">// we&#39;ve exceeded topp by including last_idx</span></span>
<span class="line">        <span class="token punctuation">}</span></span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line"></span>
<span class="line">    <span class="token comment">// sample from the truncated list</span></span>
<span class="line">    <span class="token keyword">float</span> r <span class="token operator">=</span> coin <span class="token operator">*</span> cumulative_prob<span class="token punctuation">;</span></span>
<span class="line">    <span class="token keyword">float</span> cdf <span class="token operator">=</span> <span class="token number">0.0f</span><span class="token punctuation">;</span></span>
<span class="line">    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;=</span> last_idx<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span></span>
<span class="line">        cdf <span class="token operator">+=</span> probindex<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>prob<span class="token punctuation">;</span></span>
<span class="line">        <span class="token keyword">if</span> <span class="token punctuation">(</span>r <span class="token operator">&lt;</span> cdf<span class="token punctuation">)</span> <span class="token punctuation">{</span></span>
<span class="line">            <span class="token keyword">return</span> probindex<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>index<span class="token punctuation">;</span></span>
<span class="line">        <span class="token punctuation">}</span></span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line">    <span class="token keyword">return</span> probindex<span class="token punctuation">[</span>last_idx<span class="token punctuation">]</span><span class="token punctuation">.</span>index<span class="token punctuation">;</span> <span class="token comment">// in case of rounding errors</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="reference" tabindex="-1"><a class="header-anchor" href="#reference"><span>Reference</span></a></h2>`,15),ds={href:"https://www.youtube.com/watch?v=n9TlOhRjYoc&t=60s",target:"_blank",rel:"noopener noreferrer"},ys={href:"https://www.youtube.com/watch?v=N6aRv06iv2g&t=1574s",target:"_blank",rel:"noopener noreferrer"},vs={href:"https://www.youtube.com/watch?v=nzqlFIcCSWQ",target:"_blank",rel:"noopener noreferrer"};function ks(bs,xs){const t=i("ExternalLinkIcon");return p(),m("div",null,[r,s("p",null,[o,s("a",h,[a("Moonshot AI - 开放平台"),l(t)])]),u,s("ul",null,[g,d,s("li",null,[s("p",null,[a("self attention之前就有人提出类似的机制，但是不叫这个名字，在"),s("a",y,[a("[1706.03762] Attention Is All You Need"),l(t)]),a(" 中正式提出，同时提出了Transformer")])]),v]),k,b,x,w,f,z,_,M,P,q,L,E,j,A,W,T,I,S,N,D,F,V,C,K,B,O,Q,R,Y,$,G,J,H,U,X,Z,ss,as,ns,ts,ls,es,s("ul",null,[s("li",null,[s("a",is,[a("函数光滑近似（2）：softmax与argmax | Erwin Feng Blog"),l(t)])]),s("li",null,[s("a",ps,[a("分析与拓展：多分类模型的输出为什么使用softmax？ | Erwin Feng Blog"),l(t)])])]),ms,cs,rs,os,hs,us,gs,s("ul",null,[s("li",null,[s("a",ds,[a("李宏毅【機器學習2021】Transformer (上) - YouTube"),l(t)])]),s("li",null,[s("a",ys,[a("李宏毅【機器學習2021】Transformer (下) - YouTube"),l(t)])]),s("li",null,[s("a",vs,[a("李沐Transformer论文逐段精读 - YouTube"),l(t)])])])])}const fs=e(c,[["render",ks],["__file","damoxingdiercilihui.html.vue"]]),zs=JSON.parse('{"path":"/docs/ai/damoxingdiercilihui.html","title":"大模型第二次例会","lang":"zh-CN","frontmatter":{"title":"大模型第二次例会","author":"saber","date":"2024/9/9"},"headers":[{"level":2,"title":"前置条件","slug":"前置条件","link":"#前置条件","children":[]},{"level":2,"title":"大概纲要","slug":"大概纲要","link":"#大概纲要","children":[]},{"level":2,"title":"Transformer","slug":"transformer","link":"#transformer","children":[]},{"level":2,"title":"API 参数","slug":"api-参数","link":"#api-参数","children":[{"level":3,"title":"关于softmax","slug":"关于softmax","link":"#关于softmax","children":[]},{"level":3,"title":"Sampling","slug":"sampling","link":"#sampling","children":[]}]},{"level":2,"title":"Reference","slug":"reference","link":"#reference","children":[]}],"git":{"createdTime":1725811061000,"updatedTime":1725811061000,"contributors":[{"name":"saber","email":"wuyacwc@gmail.com","commits":1}]},"filePathRelative":"docs/ai/大模型第二次例会.md"}');export{fs as comp,zs as data};
